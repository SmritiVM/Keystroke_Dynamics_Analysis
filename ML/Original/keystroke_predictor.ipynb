{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import networkx as nx\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0    s002             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1    s002             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2    s002             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3    s002             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4    s002             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "\n",
       "   DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0  0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1  0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2  0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3  0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4  0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "\n",
       "   UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0  0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1  0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2  0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3  0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4  0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DSL-StrongPasswordData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = df['subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_int = {subject: i  for i, subject in enumerate(subjects)}\n",
    "int_to_subjects = {i: subject for i, subject in enumerate(subjects)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raahu\\AppData\\Local\\Temp\\ipykernel_15612\\1725018810.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace(subjects_to_int)\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(subjects_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sessionIndex</th>\n",
       "      <th>rep</th>\n",
       "      <th>H.period</th>\n",
       "      <th>DD.period.t</th>\n",
       "      <th>UD.period.t</th>\n",
       "      <th>H.t</th>\n",
       "      <th>DD.t.i</th>\n",
       "      <th>UD.t.i</th>\n",
       "      <th>H.i</th>\n",
       "      <th>...</th>\n",
       "      <th>H.a</th>\n",
       "      <th>DD.a.n</th>\n",
       "      <th>UD.a.n</th>\n",
       "      <th>H.n</th>\n",
       "      <th>DD.n.l</th>\n",
       "      <th>UD.n.l</th>\n",
       "      <th>H.l</th>\n",
       "      <th>DD.l.Return</th>\n",
       "      <th>UD.l.Return</th>\n",
       "      <th>H.Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2558</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.2756</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.2332</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.2387</td>\n",
       "      <td>0.0813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1676</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.2517</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n",
       "0        0             1    1    0.1491       0.3979       0.2488  0.1069   \n",
       "1        0             1    2    0.1111       0.3451       0.2340  0.0694   \n",
       "2        0             1    3    0.1328       0.2072       0.0744  0.0731   \n",
       "3        0             1    4    0.1291       0.2515       0.1224  0.1059   \n",
       "4        0             1    5    0.1249       0.2317       0.1068  0.0895   \n",
       "\n",
       "   DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n",
       "0  0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n",
       "1  0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n",
       "2  0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n",
       "3  0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n",
       "4  0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n",
       "\n",
       "   UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n",
       "0  0.2583  0.1338       0.3509       0.2171    0.0742  \n",
       "1  0.1496  0.0839       0.2756       0.1917    0.0747  \n",
       "2  0.1533  0.1085       0.2847       0.1762    0.0945  \n",
       "3  0.1475  0.0845       0.3232       0.2387    0.0813  \n",
       "4  0.1633  0.0903       0.2517       0.1614    0.0818  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      1.      1.     ...  0.3509  0.2171  0.0742]\n",
      " [ 0.      1.      2.     ...  0.2756  0.1917  0.0747]\n",
      " [ 0.      1.      3.     ...  0.2847  0.1762  0.0945]\n",
      " ...\n",
      " [50.      8.     48.     ...  0.2017  0.0983  0.0905]\n",
      " [50.      8.     49.     ...  0.1917  0.0938  0.0931]\n",
      " [50.      8.     50.     ...  0.1993  0.1186  0.1018]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20400, 34)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = df.values\n",
    "print(data_raw)\n",
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.491e-01 3.979e-01 2.488e-01 ... 3.509e-01 2.171e-01 0.000e+00]\n",
      " [1.111e-01 3.451e-01 2.340e-01 ... 2.756e-01 1.917e-01 0.000e+00]\n",
      " [1.328e-01 2.072e-01 7.440e-02 ... 2.847e-01 1.762e-01 0.000e+00]\n",
      " ...\n",
      " [9.390e-02 1.189e-01 2.500e-02 ... 2.017e-01 9.830e-02 5.000e+01]\n",
      " [9.230e-02 1.294e-01 3.710e-02 ... 1.917e-01 9.380e-02 5.000e+01]\n",
      " [5.960e-02 1.310e-01 7.140e-02 ... 1.993e-01 1.186e-01 5.000e+01]]\n"
     ]
    }
   ],
   "source": [
    "data=data_raw[ :, 3:-1]\n",
    "labels_raw = df['subject'].values\n",
    "labels= labels_raw.reshape(labels_raw.shape[0],1)\n",
    "data=np.hstack([data, labels])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20400, 30)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "x=data[ : , :-1]\n",
    "y=data[:,-1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train, num_classes=51)\n",
    "Y_test=to_categorical(y_test,num_classes=51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18360, 30, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the entire model from the file\n",
    "rnn = load_model('LSTM.h5')\n",
    "# rnn = load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2040, 30, 1)\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "[10, 19, 1, 16, 8, 17, 28, 25, 42, 24, 29, 14, 28, 22, 23, 19, 27, 9, 17, 6, 14, 17, 31, 15, 14, 10, 40, 3, 32, 26, 13, 24, 32, 37, 22, 20, 41, 30, 0, 26, 10, 47, 14, 23, 31, 29, 40, 35, 13, 43, 0, 28, 7, 17, 3, 13, 13, 29, 19, 12, 3, 30, 15, 2, 40, 41, 23, 12, 47, 35, 28, 18, 23, 30, 27, 18, 33, 28, 40, 43, 7, 31, 14, 41, 48, 26, 3, 44, 19, 4, 28, 19, 18, 19, 30, 19, 24, 36, 36, 3, 39, 10, 15, 25, 14, 16, 36, 33, 50, 45, 18, 3, 9, 10, 35, 31, 45, 14, 41, 1, 22, 0, 29, 1, 34, 27, 2, 22, 41, 14, 21, 0, 39, 30, 20, 29, 19, 22, 45, 44, 2, 50, 22, 12, 13, 21, 43, 39, 47, 23, 0, 30, 21, 12, 4, 12, 26, 6, 13, 35, 32, 4, 41, 7, 16, 23, 3, 21, 35, 13, 35, 2, 49, 28, 1, 13, 32, 39, 13, 36, 10, 42, 34, 18, 4, 15, 9, 11, 7, 40, 37, 26, 30, 5, 8, 10, 16, 18, 3, 24, 14, 29, 24, 36, 14, 45, 12, 9, 35, 47, 13, 40, 49, 48, 33, 42, 29, 24, 18, 32, 36, 11, 9, 42, 35, 27, 22, 35, 25, 18, 47, 35, 7, 9, 15, 42, 4, 38, 16, 29, 0, 45, 47, 38, 16, 8, 12, 5, 32, 33, 8, 19, 13, 23, 5, 36, 10, 9, 11, 27, 12, 9, 49, 48, 12, 22, 19, 45, 17, 41, 31, 46, 39, 39, 22, 44, 48, 24, 39, 47, 9, 44, 20, 37, 39, 6, 6, 41, 33, 40, 20, 5, 6, 31, 39, 26, 48, 35, 5, 30, 3, 3, 17, 47, 33, 28, 24, 45, 39, 11, 7, 42, 23, 34, 2, 3, 0, 38, 32, 2, 46, 15, 0, 6, 27, 50, 26, 10, 0, 10, 34, 8, 3, 38, 48, 15, 19, 29, 9, 10, 17, 28, 28, 20, 1, 10, 36, 8, 33, 0, 30, 11, 11, 28, 37, 35, 7, 16, 20, 32, 44, 29, 35, 40, 36, 12, 36, 41, 17, 24, 20, 46, 40, 2, 8, 45, 0, 43, 45, 38, 6, 18, 14, 23, 27, 21, 27, 8, 47, 32, 41, 28, 10, 8, 42, 35, 6, 4, 43, 27, 41, 36, 23, 16, 24, 20, 47, 12, 29, 43, 11, 28, 17, 28, 20, 45, 15, 18, 50, 27, 0, 35, 32, 34, 49, 42, 5, 6, 4, 26, 32, 16, 37, 45, 8, 48, 8, 12, 13, 4, 27, 9, 30, 16, 24, 32, 45, 24, 30, 38, 44, 4, 12, 22, 14, 2, 17, 33, 6, 25, 9, 43, 27, 27, 11, 27, 48, 7, 12, 21, 15, 0, 9, 17, 13, 6, 27, 0, 49, 18, 23, 35, 47, 25, 14, 14, 49, 6, 39, 20, 13, 21, 3, 23, 4, 21, 39, 29, 4, 34, 4, 49, 3, 0, 7, 12, 40, 25, 30, 35, 5, 17, 32, 37, 23, 33, 32, 47, 45, 49, 22, 38, 48, 10, 35, 41, 44, 31, 3, 14, 29, 40, 24, 33, 49, 44, 18, 37, 22, 41, 28, 33, 30, 27, 6, 31, 42, 8, 24, 31, 3, 2, 23, 21, 28, 47, 44, 23, 4, 2, 21, 24, 23, 14, 47, 14, 31, 43, 35, 19, 37, 18, 26, 23, 2, 16, 4, 26, 50, 10, 23, 50, 14, 44, 17, 45, 17, 16, 37, 6, 49, 34, 33, 44, 13, 6, 45, 20, 31, 34, 47, 9, 16, 5, 17, 46, 8, 49, 27, 21, 1, 33, 12, 14, 44, 14, 43, 7, 45, 48, 10, 29, 23, 23, 36, 26, 12, 9, 43, 11, 45, 47, 30, 27, 49, 32, 10, 32, 20, 40, 40, 32, 40, 18, 17, 13, 12, 18, 2, 3, 31, 1, 17, 36, 26, 40, 48, 12, 31, 13, 50, 13, 22, 44, 3, 39, 6, 4, 43, 35, 38, 18, 14, 35, 22, 1, 22, 19, 6, 3, 44, 2, 26, 8, 45, 34, 38, 31, 48, 33, 29, 24, 40, 37, 48, 50, 25, 50, 47, 13, 1, 33, 43, 17, 7, 39, 42, 36, 23, 31, 3, 44, 35, 47, 17, 45, 18, 46, 47, 37, 36, 35, 14, 13, 32, 43, 33, 40, 0, 12, 2, 23, 49, 50, 41, 20, 27, 7, 11, 31, 16, 47, 3, 43, 29, 19, 32, 5, 29, 31, 44, 20, 29, 50, 49, 19, 10, 18, 20, 3, 14, 12, 42, 43, 13, 48, 12, 13, 3, 37, 13, 18, 42, 2, 22, 45, 16, 30, 7, 2, 23, 9, 0, 33, 37, 10, 50, 38, 28, 21, 1, 11, 23, 11, 0, 29, 13, 18, 21, 3, 22, 45, 24, 35, 38, 35, 7, 8, 24, 20, 27, 3, 23, 31, 16, 39, 4, 40, 2, 0, 0, 36, 17, 39, 16, 26, 2, 16, 32, 29, 9, 42, 41, 28, 43, 48, 47, 28, 7, 29, 22, 2, 19, 11, 13, 42, 11, 2, 2, 35, 15, 9, 12, 25, 43, 17, 24, 23, 10, 18, 23, 9, 40, 35, 14, 24, 33, 13, 44, 12, 7, 4, 43, 16, 11, 12, 16, 34, 45, 23, 28, 16, 3, 33, 24, 10, 18, 36, 47, 12, 11, 22, 19, 8, 48, 2, 1, 40, 14, 15, 8, 26, 38, 27, 8, 44, 21, 40, 21, 23, 39, 49, 26, 48, 37, 37, 45, 43, 38, 24, 37, 19, 30, 14, 8, 22, 23, 8, 36, 20, 31, 33, 0, 42, 5, 43, 24, 30, 8, 2, 40, 2, 16, 19, 31, 16, 33, 16, 31, 46, 17, 16, 31, 25, 26, 10, 39, 34, 49, 14, 18, 8, 0, 9, 33, 47, 17, 46, 16, 48, 4, 31, 38, 18, 39, 7, 36, 11, 48, 16, 9, 5, 19, 10, 8, 38, 19, 45, 2, 13, 9, 16, 40, 10, 38, 8, 43, 25, 41, 9, 14, 34, 44, 42, 11, 0, 1, 44, 3, 15, 29, 3, 0, 34, 31, 32, 0, 4, 45, 11, 48, 23, 34, 0, 36, 15, 27, 49, 42, 40, 48, 49, 14, 42, 6, 6, 25, 18, 13, 5, 26, 41, 36, 32, 49, 2, 22, 37, 40, 40, 28, 5, 50, 5, 40, 2, 16, 30, 5, 48, 11, 18, 47, 34, 11, 1, 9, 34, 46, 18, 12, 33, 31, 30, 5, 10, 34, 27, 40, 29, 49, 27, 27, 36, 32, 6, 24, 2, 6, 27, 8, 16, 19, 16, 24, 40, 0, 36, 18, 40, 20, 43, 25, 31, 27, 20, 11, 49, 13, 4, 20, 36, 39, 35, 44, 12, 24, 35, 36, 39, 28, 18, 44, 44, 18, 0, 18, 23, 7, 30, 2, 27, 39, 32, 6, 12, 49, 38, 39, 1, 44, 45, 21, 28, 38, 24, 46, 44, 13, 30, 2, 26, 17, 4, 42, 31, 39, 40, 6, 48, 17, 45, 13, 17, 30, 47, 41, 3, 17, 22, 45, 40, 33, 26, 46, 37, 33, 33, 4, 47, 39, 1, 38, 28, 46, 13, 33, 48, 8, 23, 28, 19, 23, 46, 21, 13, 26, 2, 41, 41, 22, 39, 11, 48, 31, 16, 23, 6, 48, 9, 16, 36, 39, 22, 14, 7, 15, 36, 29, 36, 48, 26, 35, 28, 41, 36, 35, 20, 20, 3, 31, 33, 22, 22, 10, 35, 19, 28, 31, 39, 23, 50, 20, 27, 27, 14, 49, 17, 11, 31, 45, 32, 3, 18, 36, 40, 48, 15, 6, 49, 50, 43, 11, 38, 7, 32, 41, 31, 48, 1, 4, 4, 18, 12, 22, 24, 21, 45, 3, 46, 6, 47, 50, 15, 29, 30, 7, 16, 44, 16, 8, 30, 45, 5, 42, 36, 11, 37, 6, 35, 43, 15, 30, 43, 43, 24, 9, 39, 27, 21, 16, 24, 1, 45, 1, 14, 18, 13, 40, 43, 10, 25, 16, 2, 30, 37, 17, 30, 27, 7, 10, 23, 27, 22, 43, 17, 11, 12, 29, 10, 6, 38, 20, 3, 2, 16, 46, 47, 42, 15, 50, 11, 16, 16, 49, 33, 32, 1, 2, 5, 36, 6, 17, 10, 42, 28, 43, 33, 6, 18, 20, 41, 19, 17, 4, 5, 33, 35, 30, 37, 37, 27, 8, 41, 37, 37, 42, 23, 9, 42, 10, 23, 44, 41, 15, 50, 10, 7, 25, 31, 45, 41, 9, 0, 1, 24, 31, 50, 35, 14, 31, 15, 12, 41, 25, 25, 29, 47, 44, 42, 10, 4, 33, 13, 10, 50, 8, 46, 34, 25, 6, 17, 10, 43, 17, 2, 48, 39, 31, 40, 44, 1, 38, 5, 40, 41, 36, 30, 23, 21, 25, 30, 20, 3, 3, 23, 31, 14, 32, 5, 12, 45, 31, 33, 42, 14, 16, 37, 45, 28, 35, 13, 3, 45, 37, 21, 29, 4, 49, 34, 46, 41, 24, 23, 2, 50, 20, 6, 30, 49, 23, 36, 31, 1, 10, 2, 8, 7, 17, 28, 20, 5, 3, 28, 35, 29, 11, 29, 11, 18, 22, 35, 9, 49, 39, 19, 26, 5, 25, 38, 25, 26, 27, 42, 44, 28, 18, 47, 38, 22, 34, 36, 35, 18, 44, 10, 1, 10, 25, 4, 14, 27, 23, 33, 22, 48, 31, 9, 19, 45, 7, 43, 38, 50, 27, 6, 42, 14, 24, 4, 50, 11, 22, 32, 3, 17, 6, 6, 0, 32, 36, 49, 25, 19, 25, 26, 22, 8, 45, 40, 35, 19, 10, 11, 16, 32, 18, 9, 30, 38, 33, 28, 42, 38, 50, 34, 35, 12, 12, 32, 8, 22, 25, 5, 48, 0, 47, 8, 5, 28, 35, 16, 24, 28, 25, 11, 33, 33, 41, 20, 9, 12, 23, 26, 8, 47, 31, 33, 23, 41, 11, 48, 21, 30, 38, 47, 24, 8, 48, 42, 18, 28, 23, 40, 13, 39, 4, 9, 15, 48, 41, 34, 47, 21, 19, 19, 5, 19, 32, 17, 24, 30, 34, 5, 23, 1, 20, 8, 1, 19, 24, 46, 1, 37, 3, 50, 8, 6, 30, 12, 9, 49, 41, 17, 18, 8, 38, 37, 42, 49, 32, 50, 0, 50, 13, 20, 24, 38, 43, 46, 15, 26, 27, 1, 48, 40, 10, 6, 30, 35, 30, 26, 21, 1, 26, 13, 9, 26, 28, 39, 9, 13, 33, 44, 39, 49, 22, 7, 27, 4, 26, 35, 39, 16, 10, 46, 35, 11, 19, 47, 1, 18, 19, 12, 33, 31, 34, 40, 6, 50, 17, 10, 48, 33, 49, 48, 36, 42, 3, 49, 31, 37, 35, 29, 48, 48, 14, 46, 10, 49, 35, 39, 9, 5, 22, 6, 6, 39, 6, 47, 25, 42, 23, 32, 29, 21, 4, 1, 44, 33, 50, 47, 6, 47, 29, 21, 42, 5, 0, 3, 34, 2, 22, 20, 18, 34, 22, 7, 47, 2, 1, 8, 45, 12, 32, 36, 49, 11, 15, 50, 25, 30, 31, 6, 38, 13, 14, 29, 0, 34, 38, 12, 44, 30, 7, 35, 14, 34, 2, 19, 15, 22, 36, 9, 49, 46, 31, 50, 13, 9, 20, 10, 22, 48, 9, 28, 24, 15, 47, 50, 8, 43, 12, 5, 39, 45, 27, 25, 50, 7, 19, 10, 31, 22, 25, 25, 7, 4, 36, 1, 20, 13, 47, 21, 26, 24, 20, 17, 42, 11, 44, 30, 42, 21, 12, 3, 19, 41, 4, 1, 5, 5, 6, 9, 7, 10, 3, 28, 0, 15, 20, 46, 18, 21, 12, 21, 5, 44, 31, 6, 29, 17, 31, 25, 34, 41, 30, 15, 2, 50, 44, 6, 31, 26, 9, 44, 11, 16, 10, 50, 32, 24, 36, 25, 22, 24, 47, 49, 38, 44, 40, 35, 15, 42, 2, 33, 12, 47, 6, 7, 19, 17, 22, 39, 27, 29, 41, 20, 48, 12, 12, 19, 50, 17, 30, 0, 8, 6, 46, 34, 17, 5, 26, 23, 17, 31, 33, 43, 23, 43, 26, 9, 32, 0, 17, 41, 2, 21, 13, 3, 8, 31, 30, 20, 10, 2, 20, 3, 50, 20, 38, 24, 21, 28, 6, 29, 7, 32, 46, 49, 41, 43, 8, 14, 34, 11, 6, 3, 47, 35, 1, 5, 47, 30, 2, 41, 4, 26, 3, 27]\n",
      "[10. 19.  1. ... 49.  3. 27.]\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "predictions_prob= rnn.predict(X_test)\n",
    "y_pred=[np.argmax(i) for i in predictions_prob]\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9397058823529412\n",
      "Precison:  0.940347262564436\n",
      "Recall:  0.9402883774434289\n",
      "F1 Score:  0.9393467846238395\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Precison: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"F1 Score: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(rnn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(rnn, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
